# -*- coding: utf-8 -*-
"""DL Final Project Report_2019320006_안희웅.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u055KmFvGygtvbuVGfmDswOt4MR-Yrzo
"""

from transformers import CLIPProcessor, CLIPModel

# CLIP 모델 다운로드
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

print("CLIP 모델 로드 완료!")

from google.colab import drive
drive.mount('/content/drive')

import os

# Google Drive의 데이터 경로
data_dir = "/content/drive/My Drive/cifake-2000"
test_fake_dir_without_cat = os.path.join(data_dir, "test-fake-without-cat")  # FAKE 이미지 경로
test_real_dir_without_cat = os.path.join(data_dir, "test-real-without-cat")  # REAL 이미지 경로

# 파일 리스트 확인
test_fake_images_without_cat = [os.path.join(test_fake_dir_without_cat, img) for img in os.listdir(test_fake_dir_without_cat)]
test_real_images_without_cat = [os.path.join(test_real_dir_without_cat, img) for img in os.listdir(test_real_dir_without_cat)]

print(f"FAKE 이미지 개수: {len(test_fake_images_without_cat)}")
print(f"REAL 이미지 개수: {len(test_real_images_without_cat)}")

prompts = [
    "This is a synthetic image generated by AI.",
    "This is a real image."
]

from PIL import Image

# 단일 이미지 예측
def predict_image(image_path, model, processor, prompts):
    image = Image.open(image_path)
    inputs = processor(text=prompts, images=image, return_tensors="pt", padding=True)
    outputs = model(**inputs)
    probs = outputs.logits_per_image.softmax(dim=1)
    return probs[0, 0].item(), probs[0, 1].item()  # FAKE 확률, REAL 확률

# 테스트
#fake_prob, real_prob = predict_image(fake_images[0], model, processor, prompts)
#print(f"FAKE 확률: {fake_prob:.2f}, REAL 확률: {real_prob:.2f}")

def evaluate_dataset(image_paths, model, processor, prompts, label):
    predictions = []
    for image_path in image_paths:
        fake_prob, real_prob = predict_image(image_path, model, processor, prompts)
        predictions.append((label, fake_prob, real_prob))
    return predictions

# 데이터셋 평가
test_fake_results_without_cat = evaluate_dataset(test_fake_images_without_cat, model, processor, prompts, "FAKE")
test_real_results_without_cat = evaluate_dataset(test_real_images_without_cat, model, processor, prompts, "REAL")

# 결과 결합
test_all_results_without_cat = test_fake_results_without_cat + test_real_results_without_cat

test_all_results_without_cat

from sklearn.metrics import classification_report

# 실제 레이블과 예측 레이블 생성
test_true_labels_without_cat = [0] * len(test_fake_results_without_cat) + [1] * len(test_real_results_without_cat)  # 0: FAKE, 1: REAL
test_predicted_labels_without_cat = [
    0 if fake_prob > real_prob else 1
    for _, fake_prob, real_prob in test_all_results_without_cat
]

# 성능 평가
print(classification_report(test_true_labels_without_cat, test_predicted_labels_without_cat, target_names=["FAKE", "REAL"]))

# Google Drive의 데이터 경로
train_data_dir = "/content/drive/My Drive/cifake-2000"
train_fake_dir = os.path.join(train_data_dir, "train-fake-without-cat")  # FAKE 이미지 경로
train_real_dir = os.path.join(train_data_dir, "train-real-without-cat")  # REAL 이미지 경로

# 파일 리스트 확인
train_fake_images = [os.path.join(train_fake_dir, img) for img in os.listdir(train_fake_dir)]
train_real_images = [os.path.join(train_real_dir, img) for img in os.listdir(train_real_dir)]

print(f"FAKE 이미지 개수: {len(train_fake_images)}")
print(f"REAL 이미지 개수: {len(train_real_images)}")

from PIL import Image
from torchvision import transforms
import torch

# 데이터 전처리
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711)),
])

# FAKE와 REAL 데이터를 전처리
def preprocess_images(image_paths, label):
    images, labels = [], []
    for img_path in image_paths:
        img = Image.open(img_path).convert("RGB")
        img_tensor = preprocess(img)
        images.append(img_tensor)
        labels.append(label)
    return images, labels

# FAKE와 REAL 데이터 전처리
processed_fake_images, fake_labels = preprocess_images(train_fake_images, label=0)  # FAKE = 0
processed_real_images, real_labels = preprocess_images(train_real_images, label=1)  # REAL = 1

# 데이터 병합
train_images = torch.stack(processed_fake_images + processed_real_images)
train_labels = torch.tensor(fake_labels + real_labels)

print(f"전체 학습 이미지 개수: {train_images.shape[0]}")

from torch.utils.data import DataLoader, TensorDataset

# TensorDataset 및 DataLoader 생성
train_dataset = TensorDataset(train_images, train_labels)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

print(f"배치당 데이터 개수: {len(next(iter(train_loader))[0])}")

device = "cuda" if torch.cuda.is_available() else "cpu"
model = model.to(device)

# Vision Encoder와 Text Encoder 학습 가능 상태로 설정
for param in model.vision_model.parameters():
    param.requires_grad = True

for param in model.text_model.parameters():
    param.requires_grad = True

import torch
import torch.nn.functional as F

# Contrastive Loss 정의
def contrastive_loss(image_features, text_features, temperature=0.07):
    """
    CLIP-style contrastive loss for image and text embeddings.
    """
    # 코사인 유사도 계산
    logits_per_image = image_features @ text_features.T / temperature
    logits_per_text = text_features @ image_features.T / temperature

    # 정답 레이블 생성
    labels = torch.arange(logits_per_image.size(0)).to(image_features.device)

    # CrossEntropyLoss를 사용해 Positive Pair 최적화
    loss_i2t = F.cross_entropy(logits_per_image, labels)  # 이미지 → 텍스트 매칭 손실
    loss_t2i = F.cross_entropy(logits_per_text, labels)  # 텍스트 → 이미지 매칭 손실

    # 평균 손실 반환
    return (loss_i2t + loss_t2i) / 2

from torch.optim import AdamW

# 옵티마이저 정의
optimizer = AdamW(model.parameters(), lr=1e-5)

# 학습 루프
epochs = 5  # 학습 반복 횟수
temperature = 0.07  # Contrastive Learning의 온도 파라미터

model.train()  # 학습 모드로 설정

for epoch in range(epochs):
    total_loss = 0
    for images, labels in train_loader:
        images = images.to(device)

        # 텍스트 프롬프트 처리 (labels에 따라 프롬프트 선택)
        text_inputs = [prompts[label] for label in labels.cpu().numpy()]

        # Processor 없이 입력 준비
        inputs = {
            "pixel_values": images,  # 정규화된 Tensor 이미지
            "input_ids": processor.tokenizer(text_inputs, padding=True, return_tensors="pt")["input_ids"].to(device)
        }

        # 모델 출력
        outputs = model(**inputs)
        image_features = outputs.image_embeds  # 이미지 임베딩
        text_features = outputs.text_embeds    # 텍스트 임베딩

        # Contrastive Loss 계산
        loss = contrastive_loss(image_features, text_features, temperature)

        # 모델 업데이트
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
    print(f"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}")

model.eval()  # 평가 모드로 설정
# 100개씩 데이터셋 평가

test_fake_results_without_cat_after_tuning = evaluate_dataset(test_fake_images_without_cat, model, processor, prompts, "FAKE")
test_real_results_without_cat_after_tuning = evaluate_dataset(test_real_images_without_cat, model, processor, prompts, "REAL")

# 결과 결합
test_results_without_cat_after_tuning = test_fake_results_without_cat_after_tuning + test_real_results_without_cat_after_tuning

test_results_without_cat_after_tuning

# 실제 레이블과 예측 레이블 생성
test_true_labels_without_cat_after_tuning = [0] * len(test_fake_results_without_cat_after_tuning) + [1] * len(test_real_results_without_cat_after_tuning)  # 0: FAKE, 1: REAL
test_predicted_labels_without_cat_after_tuning = [
    0 if fake_prob > real_prob else 1
    for _, fake_prob, real_prob in test_results_without_cat_after_tuning
]

# 성능 평가
print(classification_report(test_true_labels_without_cat_after_tuning, test_predicted_labels_without_cat_after_tuning, target_names=["FAKE", "REAL"]))

# Google Drive의 데이터 경로
data_dir = "/content/drive/My Drive/cifake-2000"
test_fake_dir_with_cat = os.path.join(data_dir, "test-fake-with-cat")  # FAKE 이미지 경로
test_real_dir_with_cat = os.path.join(data_dir, "test-real-with-cat")  # REAL 이미지 경로

# 파일 리스트 확인
test_fake_images_with_cat = [os.path.join(test_fake_dir_with_cat, img) for img in os.listdir(test_fake_dir_with_cat)]
test_real_images_with_cat = [os.path.join(test_real_dir_with_cat, img) for img in os.listdir(test_real_dir_with_cat)]

print(f"FAKE 이미지 개수: {len(test_fake_images_with_cat)}")
print(f"REAL 이미지 개수: {len(test_real_images_with_cat)}")

model.eval()  # 평가 모드로 설정
# 100개씩 데이터셋 평가

test_fake_results_with_cat_after_tuning = evaluate_dataset(test_fake_images_with_cat, model, processor, prompts, "FAKE")
test_real_results_with_cat_after_tuning = evaluate_dataset(test_real_images_with_cat, model, processor, prompts, "REAL")

# 결과 결합
test_results_with_cat_after_tuning = test_fake_results_with_cat_after_tuning + test_real_results_with_cat_after_tuning

test_results_with_cat_after_tuning

# 실제 레이블과 예측 레이블 생성
test_true_labels_with_cat_after_tuning = [0] * len(test_fake_results_with_cat_after_tuning) + [1] * len(test_real_results_with_cat_after_tuning)  # 0: FAKE, 1: REAL
test_predicted_labels_with_cat_after_tuning = [
    0 if fake_prob > real_prob else 1
    for _, fake_prob, real_prob in test_results_with_cat_after_tuning
]

# 성능 평가
print(classification_report(test_true_labels_with_cat_after_tuning, test_predicted_labels_with_cat_after_tuning, target_names=["FAKE", "REAL"]))